{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e0ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958dac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f943fd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from C:\\Users\\SMAYA\\_netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mb25cs1065\u001b[0m (\u001b[33mb25cs1065-indian-institute-of-technology-jodhpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\SMAYA\\OneDrive\\Desktop\\python\\WARP-26-INSPECT\\wandb\\run-20260206_162558-q5lg24vq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch/runs/q5lg24vq' target=\"_blank\">lively-bush-25</a></strong> to <a href='https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch' target=\"_blank\">https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch/runs/q5lg24vq' target=\"_blank\">https://wandb.ai/b25cs1065-indian-institute-of-technology-jodhpur/CNN%20on%20MNIST%20pytorch/runs/q5lg24vq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"CNN on MNIST pytorch\", save_code=True,\n",
    "           config={\n",
    "               \"batch_size\": 128,\n",
    "               \"epochs\": 20,\n",
    "               \"optimizer\": \"Adam\",\n",
    "               \"loss function\": \"CrossEntropyLoss\",\n",
    "           }\n",
    "           )\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf7325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14930b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: torch.Size([60000, 28, 28])\n",
      "training labels shape: torch.Size([60000])\n",
      "testing data shape: torch.Size([10000, 28, 28])\n",
      "testing labels shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#Prepare the MNIST dataset in this cell\n",
    "''\n",
    "train_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.RandomRotation(degrees=10),\n",
    "                                transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.7, 1.3)),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "''\n",
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
    "print(f\"training data shape: {trainset.data.shape}\")\n",
    "print(f\"training labels shape: {trainset.targets.shape}\")\n",
    "print(f\"testing data shape: {testset.data.shape}\")\n",
    "print(f\"testing labels shape: {testset.targets.shape}\")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e5b277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural_network(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (normalization1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (normalization2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (normalization3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neural_network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)#output dim = 14x14x8\n",
    "        self.conv2 = nn.Conv2d(16, 28, 3, padding =1)#output dim = 7x7x16\n",
    "        #self.dropout = nn.Dropout(p=0.15)\n",
    "        self.normalization1 = nn.BatchNorm2d(16)\n",
    "        self.normalization2 = nn.BatchNorm2d(28)\n",
    "        self.normalization3 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(28, 32, 3, padding =1)#output dim = 3x3x20\n",
    "        #self.fc1 = nn.Linear(4*4*32, 16)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        #self.fc3 = nn.Linear(16, 10)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    def forward(self,x):\n",
    "        x= self.pool(F.leaky_relu(self.normalization1(self.conv1(x))))\n",
    "        x= self.pool(F.leaky_relu(self.normalization2(self.conv2(x))))\n",
    "        x= F.leaky_relu(self.normalization3(self.conv3(x)))\n",
    "        #print(f\"Shape after conv3 and pool: {x.shape}\")\n",
    "        x = self.gap(x)\n",
    "        x= x.view(-1, 32)\n",
    "        #x= F.leaky_relu(self.fc1(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Neural_network()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725004cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 12798\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"Total number of parameters in the model: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b865b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)#does net.parameters just make a vector of all the parameters in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1e64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001CC27295F90>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{trainloader}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d7a084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepochs = 20\\nfor epoch in range(epochs):\\n    dynamic_loss = 0.0\\n    for i,data in enumerate(trainloader):\\n        inputs, labels = data[0].to(device), data[1].to(device)\\n        optimizer.zero_grad()\\n        outputs = net(inputs)\\n        loss = loss_function(outputs, F.one_hot(labels, num_classes=10).float())\\n        loss.backward()\\n        optimizer.step()\\n        dynamic_loss += loss\\n        if i%200 ==99:\\n            print(f\"epoch {epoch+1}, batch {i+1}, loss: {dynamic_loss/400}\")\\n            dynamic_loss = 0.0 \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#have to decide how to train the model in this cell ie epochs, batch size, backpropagation etc.\n",
    "'''\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    dynamic_loss = 0.0\n",
    "    for i,data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, F.one_hot(labels, num_classes=10).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        dynamic_loss += loss\n",
    "        if i%200 ==99:\n",
    "            print(f\"epoch {epoch+1}, batch {i+1}, loss: {dynamic_loss/400}\")\n",
    "            dynamic_loss = 0.0 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8780841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tqdm import tqdm\\npbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\\nfor batch_idx, (data,target) in enumerate(pbar):\\n    inputs, labels = data[0].to(device), data[1].to(device)\\n    optimizer.zero_grad()\\n    outputs = net(inputs)\\n    loss = loss_function(outputs, F.one_hot(labels, num_classes=10).float())\\n    loss.backward()\\n    optimizer.step()\\n    pbar.set_postfix({\\'loss\\': loss.item()})\\n    wandb.log({\"train_loss\": loss.item()})\\n    dynamic_loss += loss\\n    if i%200 ==99:\\n        print(f\"epoch {epoch+1}, batch {i+1}, loss: {dynamic_loss/400}\")\\n        dynamic_loss = 0.0 \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from tqdm import tqdm\n",
    "pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\n",
    "for batch_idx, (data,target) in enumerate(pbar):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = loss_function(outputs, F.one_hot(labels, num_classes=10).float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({'loss': loss.item()})\n",
    "    wandb.log({\"train_loss\": loss.item()})\n",
    "    dynamic_loss += loss\n",
    "    if i%200 ==99:\n",
    "        print(f\"epoch {epoch+1}, batch {i+1}, loss: {dynamic_loss/400}\")\n",
    "        dynamic_loss = 0.0 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1077baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, device, train_loader, optimizer, epoch):\n",
    "    net.train()\n",
    "    # tqdm creates the progress bar\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    train_correct =0\n",
    "    train_total =0\n",
    "    for i, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data)\n",
    "        loss = loss_function(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, train_predicted = torch.max(outputs, 1)\n",
    "        train_total += len(target)\n",
    "        train_correct += (train_predicted == target).sum().item()\n",
    "        # Update the bar with the latest loss\n",
    "        pbar.set_description(desc=f'Epoch {epoch} Loss={loss.item():.4f}')\n",
    "        \n",
    "        # Log training loss to wandb\n",
    "        wandb.log({\"train_loss\": loss.item(), \"train_accuracy\": 100.0 * train_correct / train_total})\n",
    "        pbar.set_postfix({'loss': loss.item(), 'train_accuracy': 100.0 * train_correct / train_total})\n",
    "\n",
    "def test(net, device, testloader):\n",
    "    net.eval()\n",
    "    correct_labels = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            test_loss += loss_function(outputs, labels).item()\n",
    "            #print(f\"outputs.data = {outputs.data}\")\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #if (predicted == labels).sum().item():\n",
    "            correct_labels += (predicted == labels).sum().item()\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = 100.0 * correct_labels / len(testloader.dataset)\n",
    "    wandb.log({\"test_accuracy\": accuracy, \"test_loss\": test_loss})\n",
    "    print(f\"\\n Test Set: Accuracy: {accuracy:.4f}%, test_loss: {test_loss} \\n\")\n",
    "# Log test results to wandb\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71c37e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct_labels = 0\\ntotal_labels = 0\\nwith torch.no_grad():\\n    for data in testloader:\\n        images, labels = data[0].to(device), data[1].to(device)\\n        outputs = net(images)\\n        probs = F.softmax(outputs, dim =1)\\n        #print(f\"outputs.data = {outputs.data}\")\\n        _, predicted = torch.max(probs, 1)\\n        total_labels += labels.size(0)\\n        #if (predicted == labels).sum().item():\\n        correct_labels += (predicted == labels).sum().item()\\n        wandb.log({\"test_accuracy\": 100*correct_labels/total_labels})\\nprint(f\"accuracy of the network on the 10000 test images: {100*correct_labels/total_labels} %\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''correct_labels = 0\n",
    "total_labels = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        probs = F.softmax(outputs, dim =1)\n",
    "        #print(f\"outputs.data = {outputs.data}\")\n",
    "        _, predicted = torch.max(probs, 1)\n",
    "        total_labels += labels.size(0)\n",
    "        #if (predicted == labels).sum().item():\n",
    "        correct_labels += (predicted == labels).sum().item()\n",
    "        wandb.log({\"test_accuracy\": 100*correct_labels/total_labels})\n",
    "print(f\"accuracy of the network on the 10000 test images: {100*correct_labels/total_labels} %\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss=2.3467:  13%|█▎        | 61/469 [00:09<00:56,  7.22it/s, loss=2.35, train_accuracy=11.4]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, config.epochs + 1):\n",
    "    train(net, device, trainloader, optimizer, epoch)\n",
    "    test_accuracy = test(net, device, testloader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
